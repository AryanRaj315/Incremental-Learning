{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, 'ICARL/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'EfficientNet-PyTorch'...\n",
      "remote: Enumerating objects: 382, done.\u001b[K\n",
      "remote: Total 382 (delta 0), reused 0 (delta 0), pack-reused 382\u001b[K\n",
      "Receiving objects: 100% (382/382), 1.04 MiB | 0 bytes/s, done.\n",
      "Resolving deltas: 100% (196/196), done.\n",
      "Checking connectivity... done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/lukemelas/EfficientNet-PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training examples for classes range(0, 3)\n",
      "0 new classes\n",
      "Epoch [1/5], Iter [100/101] Loss: 0.0238\n",
      "Epoch [2/5], Iter [100/101] Loss: 0.0335\n",
      "Epoch [3/5], Iter [100/101] Loss: 0.0006\n",
      "Epoch [4/5], Iter [100/101] Loss: 0.0012\n",
      "Epoch [5/5], Iter [100/101] Loss: 0.0144\n",
      "Constructing exemplar set for class-0...\n",
      "Done\n",
      "Constructing exemplar set for class-1...\n",
      "Done\n",
      "Constructing exemplar set for class-2...\n",
      "Done\n",
      "Exemplar set for class-0: (666, 28, 28, 3)\n",
      "Exemplar set for class-1: (666, 28, 28, 3)\n",
      "Exemplar set for class-2: (666, 28, 28, 3)\n",
      "mnist classes: 3\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "Computing mean of exemplars...\n",
      "Done\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([65, 3, 28, 28])\n",
      "Train Accuracy: 63 %\n",
      "Test Accuracy: 64 %\n",
      "Loading training examples for classes range(3, 6)\n",
      "3 new classes\n",
      "Epoch [1/5], Iter [100/111] Loss: 0.8846\n",
      "Epoch [2/5], Iter [100/111] Loss: 0.8805\n",
      "Epoch [3/5], Iter [100/111] Loss: 0.7378\n",
      "Epoch [4/5], Iter [100/111] Loss: 0.7724\n",
      "Epoch [5/5], Iter [100/111] Loss: 0.8851\n",
      "Constructing exemplar set for class-3...\n",
      "Done\n",
      "Constructing exemplar set for class-4...\n",
      "Done\n",
      "Constructing exemplar set for class-5...\n",
      "Done\n",
      "Exemplar set for class-0: (333, 28, 28, 3)\n",
      "Exemplar set for class-1: (333, 28, 28, 3)\n",
      "Exemplar set for class-2: (333, 28, 28, 3)\n",
      "Exemplar set for class-3: (333, 28, 28, 3)\n",
      "Exemplar set for class-4: (333, 28, 28, 3)\n",
      "Exemplar set for class-5: (333, 28, 28, 3)\n",
      "mnist classes: 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "Computing mean of exemplars...\n",
      "Done\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([8, 3, 28, 28])\n",
      "Train Accuracy: 80 %\n",
      "Test Accuracy: 76 %\n",
      "Loading training examples for classes range(6, 9)\n",
      "3 new classes\n",
      "Epoch [1/5], Iter [100/114] Loss: 1.7449\n",
      "Epoch [2/5], Iter [100/114] Loss: 1.6793\n",
      "Epoch [3/5], Iter [100/114] Loss: 1.5920\n",
      "Epoch [4/5], Iter [100/114] Loss: 1.7176\n",
      "Epoch [5/5], Iter [100/114] Loss: 1.6585\n",
      "Constructing exemplar set for class-6...\n",
      "Done\n",
      "Constructing exemplar set for class-7...\n",
      "Done\n",
      "Constructing exemplar set for class-8...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "Exemplar set for class-0: (222, 28, 28, 3)\n",
      "Exemplar set for class-1: (222, 28, 28, 3)\n",
      "Exemplar set for class-2: (222, 28, 28, 3)\n",
      "Exemplar set for class-3: (222, 28, 28, 3)\n",
      "Exemplar set for class-4: (222, 28, 28, 3)\n",
      "Exemplar set for class-5: (222, 28, 28, 3)\n",
      "Exemplar set for class-6: (222, 28, 28, 3)\n",
      "Exemplar set for class-7: (222, 28, 28, 3)\n",
      "Exemplar set for class-8: (222, 28, 28, 3)\n",
      "mnist classes: 9\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "Computing mean of exemplars...\n",
      "Done\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([7, 3, 28, 28])\n",
      "Train Accuracy: 89 %\n",
      "Test Accuracy: 38 %\n",
      "Loading training examples for classes range(9, 12)\n",
      "1 new classes\n",
      "Constructing exemplar set for class-9...\n",
      "Done\n",
      "Exemplar set for class-0: (200, 28, 28, 3)\n",
      "Exemplar set for class-1: (200, 28, 28, 3)\n",
      "Exemplar set for class-2: (200, 28, 28, 3)\n",
      "Exemplar set for class-3: (200, 28, 28, 3)\n",
      "Exemplar set for class-4: (200, 28, 28, 3)\n",
      "Exemplar set for class-5: (200, 28, 28, 3)\n",
      "Exemplar set for class-6: (200, 28, 28, 3)\n",
      "Exemplar set for class-7: (200, 28, 28, 3)\n",
      "Exemplar set for class-8: (200, 28, 28, 3)\n",
      "Exemplar set for class-9: (200, 28, 28, 3)\n",
      "mnist classes: 10\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "Computing mean of exemplars...\n",
      "Done\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([128, 3, 28, 28])\n",
      "images shape before going to classify:  torch.Size([42, 3, 28, 28])\n",
      "Train Accuracy: 66 %\n",
      "Test Accuracy: 57 %\n"
     ]
    }
   ],
   "source": [
    "!python ICARL/main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KAGGLE_USERNAME\"] = \"aryanraj111315\"\n",
    "os.environ[\"KAGGLE_KEY\"] = \"fe62f9b8e276ad1e28c6f4c59045c2f8\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading digit-recognizer.zip to /notebooks/Incremental-Learning\n",
      " 65%|████████████████████████▊             | 10.0M/15.3M [00:00<00:00, 11.0MB/s]\n",
      "100%|██████████████████████████████████████| 15.3M/15.3M [00:00<00:00, 36.0MB/s]\n"
     ]
    }
   ],
   "source": [
    "!kaggle competitions download -c digit-recognizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = train[\"label\"]\n",
    "\n",
    "# Drop 'label' column\n",
    "X_train = train.drop(labels = [\"label\"],axis = 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train / 255.0\n",
    "test = test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.values.reshape(-1,28,28,1)\n",
    "test = test.values.reshape(-1,28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 28, 28, 1)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0][:,:,0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray = X_train[18][:,:,0].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f9179399e50>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "color = cv2.cvtColor(gray,cv2.COLOR_GRAY2RGB)\n",
    "plt.imshow(color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
